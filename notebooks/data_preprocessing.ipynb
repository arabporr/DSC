{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5667e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592641a5",
   "metadata": {},
   "source": [
    "## Loading data and initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/options_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for readability\n",
    "new_names = {\n",
    "    \"Option_type\": \"option_type\",\n",
    "    \"S\": \"stock_price\",\n",
    "    \"K\": \"strike_price\",\n",
    "    \"T\": \"time_to_maturity\",\n",
    "    \"r\": \"interest_rate\",\n",
    "    \"sigma\": \"volatility\",\n",
    "    \"q\": \"dividend_yield\",\n",
    "    \"bs_price\": \"black_scholes_price\",\n",
    "    \"mc_price\": \"monte_carlo_price\",\n",
    "}\n",
    "\n",
    "df.rename(columns=new_names, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical type\n",
    "df[\"option_type\"] = df[\"option_type\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a93b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round prices to 4 decimal places\n",
    "df = df.round(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb2171",
   "metadata": {},
   "source": [
    "### Verifying the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77c03d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        option_type  stock_price  strike_price  time_to_maturity  \\\n",
      "0             call         50.0           100              0.08   \n",
      "1             call         50.0           100              0.08   \n",
      "2             call         50.0           100              0.08   \n",
      "3             call         50.0           100              0.08   \n",
      "4             call         50.0           100              0.08   \n",
      "...            ...          ...           ...               ...   \n",
      "152995         put        150.0           100              5.00   \n",
      "152996         put        150.0           100              5.00   \n",
      "152997         put        150.0           100              5.00   \n",
      "152998         put        150.0           100              5.00   \n",
      "152999         put        150.0           100              5.00   \n",
      "\n",
      "        interest_rate  volatility  dividend_yield  black_scholes_price  \\\n",
      "0                0.01         0.1            0.00               0.0000   \n",
      "1                0.01         0.1            0.01               0.0000   \n",
      "2                0.01         0.1            0.02               0.0000   \n",
      "3                0.01         0.1            0.03               0.0000   \n",
      "4                0.01         0.1            0.04               0.0000   \n",
      "...               ...         ...             ...                  ...   \n",
      "152995           0.10         0.4            0.05               9.6077   \n",
      "152996           0.10         0.8            0.03              29.2086   \n",
      "152997           0.10         0.8            0.02              28.6020   \n",
      "152998           0.10         0.8            0.05              30.4210   \n",
      "152999           0.10         0.8            0.04              29.8150   \n",
      "\n",
      "        monte_carlo_price  \n",
      "0                  0.0000  \n",
      "1                  0.0000  \n",
      "2                  0.0000  \n",
      "3                  0.0000  \n",
      "4                  0.0000  \n",
      "...                   ...  \n",
      "152995             9.5822  \n",
      "152996            29.1893  \n",
      "152997            28.5549  \n",
      "152998            30.5092  \n",
      "152999            29.8691  \n",
      "\n",
      "[153000 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef907bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 153000 entries, 0 to 152999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   option_type          153000 non-null  object \n",
      " 1   stock_price          153000 non-null  float64\n",
      " 2   strike_price         153000 non-null  int64  \n",
      " 3   time_to_maturity     153000 non-null  float64\n",
      " 4   interest_rate        153000 non-null  float64\n",
      " 5   volatility           153000 non-null  float64\n",
      " 6   dividend_yield       153000 non-null  float64\n",
      " 7   black_scholes_price  153000 non-null  float64\n",
      " 8   monte_carlo_price    153000 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 10.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4184d",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to a new CSV file\n",
    "if not os.path.exists(\"../data/cleaned_options_dataset.csv\"):\n",
    "    df.to_csv(\"../data/cleaned_options_dataset.csv\", index=False)\n",
    "    print(\"Cleaned data saved to CSV file.\")\n",
    "else:\n",
    "    print(\"Cleaned data already exists. No new file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e747d4",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef4c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "Numerical_features = [\n",
    "    \"stock_price\",\n",
    "    \"strike_price\",\n",
    "    \"time_to_maturity\",\n",
    "    \"interest_rate\",\n",
    "    \"volatility\",\n",
    "    \"dividend_yield\",\n",
    "]\n",
    "\n",
    "Categorical_features = [\"option_type\"]\n",
    "\n",
    "Target_column = \"black_scholes_price\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad781cf",
   "metadata": {},
   "source": [
    "### Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_columns(df):\n",
    "    \"\"\"\n",
    "    Add new columns to the DataFrame as new columns.\n",
    "    T\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing the original features.\n",
    "        Note: since we are using this function with our own generated dataset, we are already sure that the required columns are present.\n",
    "        However, to follow the standards and best practices, I am going to add the checker in the beginning of the function.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new features added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the required columns are present in the DataFrame\n",
    "    if \"stock_price\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'stock_price' column.\")\n",
    "    if \"strike_price\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'strike_price' column.\")\n",
    "    if \"time_to_maturity\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'time_to_maturity' column.\")\n",
    "    if \"volatility\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'volatility' column.\")\n",
    "    if \"interest_rate\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'interest_rate' column.\")\n",
    "    if \"dividend_yield\" not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain the 'dividend_yield' column.\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if not 0 in df[\"time_to_maturity\"].values:\n",
    "        df[\"1_over_T\"] = 1 / df[\"time_to_maturity\"]\n",
    "        df[\"log_T\"] = np.log(df[\"time_to_maturity\"])\n",
    "\n",
    "    df[\"sqrt_T\"] = np.sqrt(df[\"time_to_maturity\"])\n",
    "    df[\"log1p_T\"] = np.log1p(df[\"time_to_maturity\"])\n",
    "\n",
    "    df[\"variance\"] = df[\"volatility\"] ** 2\n",
    "\n",
    "    if not 0 in df[\"strike_price\"].values:\n",
    "        df[\"stock_over_strike\"] = df[\"stock_price\"] / df[\"strike_price\"]\n",
    "\n",
    "    if not 0 in df[\"stock_price\"].values:\n",
    "        df[\"strike_over_stock\"] = df[\"strike_price\"] / df[\"stock_price\"]\n",
    "\n",
    "    if not 0 in df[\"interest_rate\"].values:\n",
    "        df[\"volatility_over_interest\"] = df[\"volatility\"] / df[\"interest_rate\"]\n",
    "        df[\"dividend_yield_over_interest\"] = df[\"dividend_yield\"] / df[\"interest_rate\"]\n",
    "        df[\"stock_price_over_interest\"] = df[\"stock_price\"] / df[\"interest_rate\"]\n",
    "\n",
    "    if not 0 in df[\"dividend_yield\"].values:\n",
    "        df[\"volatility_over_dividend\"] = df[\"volatility\"] / df[\"dividend_yield\"]\n",
    "        df[\"interest_rate_over_dividend\"] = df[\"interest_rate\"] / df[\"dividend_yield\"]\n",
    "        df[\"stock_price_over_dividend\"] = df[\"stock_price\"] / df[\"dividend_yield\"]\n",
    "\n",
    "    if not 0 in df[\"volatility\"].values:\n",
    "        df[\"interest_rate_over_volatility\"] = df[\"interest_rate\"] / df[\"volatility\"]\n",
    "        df[\"dividend_yield_over_volatility\"] = df[\"dividend_yield\"] / df[\"volatility\"]\n",
    "        df[\"stock_price_over_volatility\"] = df[\"stock_price\"] / df[\"volatility\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Adding new columns to the DataFrame\n",
    "add_new_cols = FunctionTransformer(func=add_new_columns, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7105ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding polynomial features\n",
    "add_poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea714103",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = make_pipeline(\n",
    "    add_new_cols,\n",
    "    add_poly,\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder(drop=\"if_binary\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", numerical_pipeline, Numerical_features),\n",
    "        (\"categorical\", categorical_pipeline, Categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272ffd5",
   "metadata": {},
   "source": [
    "### Adding new features and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_1 = add_new_cols.fit_transform(df[Numerical_features])\n",
    "df_temp_2 = pd.DataFrame(\n",
    "    add_poly.fit_transform(df_temp_1),\n",
    "    columns=add_poly.get_feature_names_out(df_temp_1.columns),\n",
    ")\n",
    "df_temp_2.columns = df_temp_2.columns.str.replace(\" \", \"_times_\", regex=False)\n",
    "\n",
    "num_feature_names = df_temp_2.columns.tolist()\n",
    "\n",
    "\n",
    "df_temp_1 = pd.DataFrame(\n",
    "    categorical_pipeline.fit_transform(df[Categorical_features]).toarray(),\n",
    "    columns=categorical_pipeline.get_feature_names_out(Categorical_features),\n",
    ")\n",
    "cat_feature_names = df_temp_1.columns.tolist()\n",
    "\n",
    "\n",
    "all_feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "print(\"Pipeline tested. Output features are:\\n\", all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a8be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  option_type  stock_price  strike_price  time_to_maturity  interest_rate  \\\n",
      "0        call         50.0           100              0.08           0.01   \n",
      "1        call         50.0           100              0.08           0.01   \n",
      "2        call         50.0           100              0.08           0.01   \n",
      "3        call         50.0           100              0.08           0.01   \n",
      "4        call         50.0           100              0.08           0.01   \n",
      "\n",
      "   volatility  dividend_yield  black_scholes_price  monte_carlo_price  \\\n",
      "0         0.1            0.00                  0.0                0.0   \n",
      "1         0.1            0.01                  0.0                0.0   \n",
      "2         0.1            0.02                  0.0                0.0   \n",
      "3         0.1            0.03                  0.0                0.0   \n",
      "4         0.1            0.04                  0.0                0.0   \n",
      "\n",
      "   1_over_T  ...   log1p_T  variance  stock_over_strike  strike_over_stock  \\\n",
      "0      12.5  ...  0.076961      0.01                0.5                2.0   \n",
      "1      12.5  ...  0.076961      0.01                0.5                2.0   \n",
      "2      12.5  ...  0.076961      0.01                0.5                2.0   \n",
      "3      12.5  ...  0.076961      0.01                0.5                2.0   \n",
      "4      12.5  ...  0.076961      0.01                0.5                2.0   \n",
      "\n",
      "   volatility_over_interest  dividend_yield_over_interest  \\\n",
      "0                      10.0                           0.0   \n",
      "1                      10.0                           1.0   \n",
      "2                      10.0                           2.0   \n",
      "3                      10.0                           3.0   \n",
      "4                      10.0                           4.0   \n",
      "\n",
      "   stock_price_over_interest  interest_rate_over_volatility  \\\n",
      "0                     5000.0                            0.1   \n",
      "1                     5000.0                            0.1   \n",
      "2                     5000.0                            0.1   \n",
      "3                     5000.0                            0.1   \n",
      "4                     5000.0                            0.1   \n",
      "\n",
      "   dividend_yield_over_volatility  stock_price_over_volatility  \n",
      "0                             0.0                        500.0  \n",
      "1                             0.1                        500.0  \n",
      "2                             0.2                        500.0  \n",
      "3                             0.3                        500.0  \n",
      "4                             0.4                        500.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_data = preprocessor.fit_transform(\n",
    "    df[Numerical_features + Categorical_features]\n",
    ")\n",
    "processed_data = pd.DataFrame(processed_data, columns=all_feature_names, index=df.index)\n",
    "processed_data[Target_column] = df[Target_column]\n",
    "\n",
    "if not os.path.exists(\"../data/processed_data.csv\"):\n",
    "    processed_data.to_csv(\"../data/processed_options_dataset.csv\")\n",
    "    print(\"Processed data saved to CSV file.\")\n",
    "else:\n",
    "    print(\"Processed data already exists. No new file created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caab1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a66ed0f",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "try:\n",
    "    data = processed_data.copy()\n",
    "except:\n",
    "    data = pd.read_csv(\"../data/processed_options_dataset.csv\", index_col=0)\n",
    "\n",
    "# making sure that there is no information leakage in the dataset\n",
    "if \"monte_carlo_price\" in data.columns:\n",
    "    data = data.drop(columns=[\"monte_carlo_price\"])\n",
    "if \"mc_price\" in data.columns:\n",
    "    data = data.drop(columns=[\"mc_price\"])\n",
    "if \"bs_price\" in data.columns:\n",
    "    data = data.drop(columns=[\"bs_price\"])\n",
    "\n",
    "\n",
    "X = data.drop(columns=[\"black_scholes_price\"])\n",
    "y = data[\"black_scholes_price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=2025, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/training_data.csv\"):\n",
    "    training_data = pd.concat([X_train, y_train], axis=1)\n",
    "    training_data.to_csv(\"../data/training_data.csv\", index=False)\n",
    "    print(\"Training data saved to CSV file.\")\n",
    "else:\n",
    "    print(\"Training data already exists. No new file created.\")\n",
    "\n",
    "if not os.path.exists(\"../data/testing_data.csv\"):\n",
    "    testing_data = pd.concat([X_test, y_test], axis=1)\n",
    "    testing_data.to_csv(\"../data/testing_data.csv\", index=False)\n",
    "    print(\"Testing data saved to CSV file.\")\n",
    "else:\n",
    "    print(\"Testing data already exists. No new file created.\")\n",
    "\n",
    "print(\"Data preprocessing completed successfully.\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacb508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmo_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
